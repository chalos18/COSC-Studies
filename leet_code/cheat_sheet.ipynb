{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Methods/Patterns: Two pointers, Hash map (one pass, double pass), sorting by criteria"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Easy - *Merge strings alternately* - Pointers for both strings, increment while looping through each and append to list. \"\".join to join strings in a list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Easy - *Has duplicate* - Can use a hash map or hash set. If a hashmap then we can use **.get() - O(1) - to check if an item is in a hash map without causing an error for missing key**. To use the **hash set remember to use .add()**\n",
    "\n",
    "Time & Space Complexity\n",
    "- Hash set\n",
    "  - Time complexity: O(n)\n",
    "  - Space complexity: O(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Easy - *is Anagram* - Can use equality on a **hash map** to check if the string and string count is the same. Or, can use the advantage of the **lexicographical order of strings** by splitting using **list() - O(n) -** and sorting using **.sort() - O(nlogn) -** to then check the sorted_split_string(s) are equal to each other since they will be in the same order. Using **sorted()** does the same thing but without splitting it into a list.\n",
    "\n",
    "Time & Space Complexity\n",
    "- Using sort/sorted\n",
    "  - Time complexity: O(nlogn + mlogm)\n",
    "  - Space complexity: O(1) or O(n+m) depending on the sorting algorithm.\n",
    "\n",
    "To Note:\n",
    "- If two strings have different lengths, they cannot be anagrams. Skipping this early check means wasting time processing strings that could never match. Always compare lengths first and return false immediately if they differ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Easy* - twoSum - To brute force we can check every pair of of different elements in the array that sums up to the target but its not very efficient. Instead, we can use the **two pointers** approach which is a proper pattern. Initialize two pointers, one on each end of the array, if sum is less than target move the left pointer, if its greater than move the right pointer until the sum is equal to the target.\n",
    "\n",
    "Time & Space Complexity\n",
    "- Using sort/sorted\n",
    "  - Time complexity: O(n^2)\n",
    "  - Space complexity: O(1)\n",
    "- Using two pointers\n",
    "  - Time complexity: O(nlogn)\n",
    "  - Space complexity: O(n)\n",
    "- Using hash map (two pass)\n",
    "  - Time complexity: O(n)\n",
    "  - Space complexity: O(n)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Medium* - Group Anagrams - The brute force method is simple with a double iteration of the array checking if each word is the anagram of each other and adding to a sublist. We then filter for duplicates. This is slow and unnecesarily convoluted. \n",
    "\n",
    "We can instead use a **hash map** solution. The hash map is a defaultdict(list), this is because we need the subsets to be lists and we can take advantage of the defaultdict behaviour of defaulting to an empty list, given we pass in the factory function list. So all we have to do is iterate through the list, sorting each word and turning it into a string (the result of using **sorted** is a list) -> use **\"\".join()** to turn it into a string again. Then we initialise the sorted word into the hash map and append the original word. what we will end up with is a hash map of patterns/sorted words whose value can be appended to so that we can have every word that matches that pattern in the hash map. In the end we just need to return the values of the dict (which are sublists) and turn them into a list as .values() returns a dict type.\n",
    "\n",
    "The use of a **defaultdict** for the hash map instead of a simple dict allows for avoiding keyerror. If you try to access a key that it is not there, it automatically creates the key with a default value provided by a factory function (e.g int, list, set) which you provide upon initialisation. A standard dict is initialised with {}. \n",
    "\n",
    "**--- defaultdict ---**\n",
    "- def_dict = **defaultdict(int)** # Default value is 0\n",
    "- def_dict['a'] += 1         # Works immediately: {'a': 1}\n",
    "\n",
    "**--------------------**\n",
    "\n",
    "Time & Space Complexity\n",
    "- Using hash map\n",
    "  - Time complexity: O(m * nlogn) - where m is the length of the list and n is the number of discting items/chars\n",
    "  - Space complexity: O(m * n)\n",
    "  - Where m is the number of strings and n is the length of the longest string\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Medium* - top K Frequent - The intuitive solution I thought of was to count the frequency of each number, add to a hash map. Sort it by the count, then slice my top k by turning the hash map into a list. \n",
    "\n",
    "Bucket sort - Map the count of each value as the key of the map, then append the numbers that match the count in a list as the values. e.g the count of 3 has a list [1,4,5] which are all numbers that appear 3 times in the original list.\n",
    "\n",
    "A few things learned:\n",
    "- To use sorted on the values of the items of the list, use the **key parameter with a lambda function**. \n",
    "- To make it a descending order use reverse=True, else, leave it unspecified. \n",
    "- Dont forget to use .items() to actually apply the operations on the items of the list, else it wont work. \n",
    "- If you want to use a lambda function with a list you can use **map()** to apply the lambda function on each value of that list. \n",
    "- [-k:] Grabs the last k numbers of a list, whereas [:k] grabs the first k numbers of a list.\n",
    "- count[num] = 1 + count.get(num, 0)  -> very neat trick to get the count of hash map and add one to it. But default to 0 if the index does not exist yet to avoid a key error.\n",
    "\n",
    "Time & Space Complexity\n",
    "- Using hash map\n",
    "  - Time complexity: O(m * nlogn)\n",
    "  - Space complexity: O(m * n)\n",
    "  - Where m is the number of strings and n is the length of the longest string"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
